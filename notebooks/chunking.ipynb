{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d91415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Config loaded - Data path: d:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\notebooks\\..\\data\\processed\\filtered_complaints.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete - Processing ALL your real data\n"
     ]
    }
   ],
   "source": [
    "import sys, pandas as pd, numpy as np\n",
    "sys.path.append('..')\n",
    "from src.task2_config import DATA_PATH\n",
    "from src.loader import load_real_data\n",
    "from src.chunker import chunk_all_complaints\n",
    "from src.embedder import generate_all_embeddings\n",
    "from src.vectorstore import create_vectorstore, search\n",
    "from src.task2_reporter import create_final_summary\n",
    "print(\"âœ… Setup complete - Processing ALL your real data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9d2c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading YOUR real data: d:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\notebooks\\..\\data\\processed\\filtered_complaints.csv\n",
      "âœ… Loaded 1,814 complaints\n",
      "ðŸ“‹ Columns: ['Complaint ID', 'Date received', 'Product', 'Issue', 'Company', 'State', 'Consumer complaint narrative', 'Text_Length']\n",
      "\n",
      "ðŸ“Š Processing ALL 1,814 complaints\n",
      "ðŸ“‹ Columns: ['Complaint ID', 'Date received', 'Product', 'Issue', 'Company', 'State', 'Consumer complaint narrative', 'Text_Length']\n"
     ]
    }
   ],
   "source": [
    "df = load_real_data()\n",
    "print(f\"\\nðŸ“Š Processing ALL {len(df):,} complaints\")\n",
    "print(f\"ðŸ“‹ Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef77763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 1,814 complaints\n",
      "\n",
      "ðŸ“‹ COLUMNS:\n",
      "  â€¢ 'Complaint ID'\n",
      "  â€¢ 'Date received'\n",
      "  â€¢ 'Product'\n",
      "  â€¢ 'Issue'\n",
      "  â€¢ 'Company'\n",
      "  â€¢ 'State'\n",
      "  â€¢ 'Consumer complaint narrative'\n",
      "  â€¢ 'Text_Length'\n",
      "\n",
      "ðŸ“ Sample narrative (first 100 chars):\n",
      "XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX Apt XXXX, XXXX, TX XXXX XXXX : XX/XX/XXXX TransUnion Consume\n",
      "\n",
      "ðŸ“Š Complaints with narratives: 1,814/1,814 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "import sys, pandas as pd\n",
    "sys.path.append('..')\n",
    "from src.task2_config import DATA_PATH\n",
    "\n",
    "# Load and inspect\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"âœ… Loaded {len(df):,} complaints\")\n",
    "print(f\"\\nðŸ“‹ COLUMNS:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  â€¢ '{col}'\")\n",
    "    \n",
    "# Check the narrative column\n",
    "narrative_col = 'Consumer complaint narrative'\n",
    "if narrative_col in df.columns:\n",
    "    print(f\"\\nðŸ“ Sample narrative (first 100 chars):\")\n",
    "    print(df[narrative_col].iloc[0][:100] if pd.notna(df[narrative_col].iloc[0]) else \"EMPTY\")\n",
    "    \n",
    "    # Count non-empty narratives\n",
    "    non_empty = df[narrative_col].notna().sum()\n",
    "    print(f\"\\nðŸ“Š Complaints with narratives: {non_empty:,}/{len(df):,} ({(non_empty/len(df)*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”ª Chunking 1,814 complaints...\n",
      "ðŸ“‹ Available columns: ['Complaint ID', 'Date received', 'Product', 'Issue', 'Company', 'State', 'Consumer complaint narrative', 'Text_Length']\n",
      "ðŸ“ Using narrative column: 'Complaint ID'\n",
      "ðŸ·ï¸ Using product column: 'Product'\n",
      "\n",
      "âœ… Created 0 chunks from 1,814 complaints\n",
      "ðŸ“Š Avg chunks per complaint: 0.00\n",
      "\n",
      "ðŸ“Š Product distribution in chunks:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'product'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m chunks_df = \u001b[43mchunk_all_complaints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Created \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks_df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m total chunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ“ˆ Avg chunks/complaint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks_df)/\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\notebooks\\..\\src\\chunker.py:86\u001b[39m, in \u001b[36mchunk_all_complaints\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Show sample of product distribution\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Product distribution in chunks:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchunks_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproduct\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts().head())\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[32m     89\u001b[39m chunks_df.to_parquet(CHUNKS_PATH)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'product'"
     ]
    }
   ],
   "source": [
    "chunks_df = chunk_all_complaints(df)\n",
    "print(f\"\\nðŸ“Š Created {len(chunks_df):,} total chunks\")\n",
    "print(f\"ðŸ“ˆ Avg chunks/complaint: {len(chunks_df)/len(df):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, model = generate_all_embeddings(chunks_df)\n",
    "print(f\"\\nâœ… Embeddings complete: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, metadata = create_vectorstore(embeddings, chunks_df)\n",
    "search(\"credit card fraud\", model, index, metadata)\n",
    "create_final_summary(df, chunks_df, index)\n",
    "print(\"\\nâœ… TASK 2 COMPLETE! Check vector_store/ and reports/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
