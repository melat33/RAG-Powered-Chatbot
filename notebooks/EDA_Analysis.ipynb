{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa0d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete - Target products: ['Credit Card', 'Mortgage', 'Student Loan', 'Vehicle Loan', 'Payday Loan']\n",
      "‚úÖ Setup complete - using configuration from src/\n",
      "   Target products: ['Credit Card', 'Mortgage', 'Student Loan', 'Vehicle Loan', 'Payday Loan']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and setup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.config import RAW_DATA_PATH, PRODUCT_MAPPING, TARGET_PRODUCTS\n",
    "from src.data_loader import filter_complaints_streaming\n",
    "from src.preprocessor import prepare_final_dataset\n",
    "from src.visualizer import create_product_dashboard, create_text_length_plot\n",
    "from src.reporter import save_data_quality_report\n",
    "print(f\"‚úÖ Setup complete - Target products: {TARGET_PRODUCTS}\")\n",
    "\n",
    "print(\"‚úÖ Setup complete - using configuration from src/\")\n",
    "print(f\"   Target products: {TARGET_PRODUCTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f86082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Loading complaint database...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading data from: d:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\notebooks\\..\\data\\raw\\complaints.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   üìä Chunk 5: 250,000 records loaded\n",
      "   üìä Chunk 10: 500,000 records loaded\n",
      "   üìä Chunk 15: 750,000 records loaded\n",
      "   üìä Chunk 20: 1,000,000 records loaded\n",
      "   üìä Chunk 25: 1,250,000 records loaded\n",
      "   üìä Chunk 30: 1,500,000 records loaded\n",
      "   üìä Chunk 35: 1,750,000 records loaded\n",
      "   üìä Chunk 40: 2,000,000 records loaded\n",
      "   üìä Chunk 45: 2,250,000 records loaded\n",
      "   üìä Chunk 50: 2,500,000 records loaded\n",
      "   üìä Chunk 55: 2,750,000 records loaded\n",
      "   üìä Chunk 60: 3,000,000 records loaded\n",
      "   üìä Chunk 65: 3,250,000 records loaded\n",
      "   üìä Chunk 70: 3,500,000 records loaded\n",
      "   üìä Chunk 75: 3,750,000 records loaded\n",
      "   üìä Chunk 80: 4,000,000 records loaded\n",
      "   üìä Chunk 85: 4,250,000 records loaded\n",
      "   üìä Chunk 90: 4,500,000 records loaded\n",
      "   üìä Chunk 95: 4,750,000 records loaded\n",
      "   üìä Chunk 100: 5,000,000 records loaded\n",
      "   üìä Chunk 105: 5,250,000 records loaded\n",
      "   üìä Chunk 110: 5,500,000 records loaded\n",
      "   üìä Chunk 115: 5,750,000 records loaded\n",
      "   üìä Chunk 120: 6,000,000 records loaded\n",
      "   üìä Chunk 125: 6,250,000 records loaded\n",
      "   üìä Chunk 130: 6,500,000 records loaded\n",
      "   üìä Chunk 135: 6,750,000 records loaded\n",
      "   üìä Chunk 140: 7,000,000 records loaded\n",
      "   üìä Chunk 145: 7,250,000 records loaded\n",
      "   üìä Chunk 150: 7,500,000 records loaded\n",
      "   üìä Chunk 155: 7,750,000 records loaded\n",
      "   üìä Chunk 160: 8,000,000 records loaded\n",
      "   üìä Chunk 165: 8,250,000 records loaded\n",
      "   üìä Chunk 170: 8,500,000 records loaded\n",
      "   üìä Chunk 175: 8,750,000 records loaded\n",
      "   üìä Chunk 180: 9,000,000 records loaded\n",
      "   üìä Chunk 185: 9,250,000 records loaded\n",
      "   üìä Chunk 190: 9,500,000 records loaded\n",
      "‚úÖ Loaded complete dataset: 9,609,797 records\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load data\n",
    "from src.config import RAW_DATA_PATH\n",
    "from src.data_loader import load_complaints_data\n",
    "print(f\"üìÇ Loading data from: {RAW_DATA_PATH}\")\n",
    "\n",
    "df = load_complaints_data(RAW_DATA_PATH)\n",
    "print(f\"\\n‚úÖ Loaded {len(df):,} complaints with {len(df.columns)} features\")\n",
    "print(f\"   Date range: {df['Date received'].min()} to {df['Date received'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f6d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Product mapping complete\n",
      "üìä Filtered to 265,782 business-relevant complaints with narratives\n",
      "\n",
      "üìä Product categories:\n",
      "   ‚Ä¢ Mortgage: 130,160\n",
      "   ‚Ä¢ Credit Card: 80,667\n",
      "   ‚Ä¢ Student Loan: 53,209\n",
      "   ‚Ä¢ Payday Loan: 1,746\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Product mapping and filtering\n",
    "from src.preprocessor import fast_filter_pipeline\n",
    "\n",
    "df_filtered = fast_filter_pipeline(df)\n",
    "print(\"\\nüìä Product categories:\")\n",
    "product_counts = df_filtered['Product_Category'].value_counts()\n",
    "for product, count in product_counts.items():\n",
    "    print(f\"   ‚Ä¢ {product}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final dataset: 265,694 complaints ready for analysis\n",
      "üìä Products: {'Mortgage': 130134, 'Credit Card': 80620, 'Student Loan': 53194, 'Payday Loan': 1746}\n",
      "‚úÖ Text cleaning complete\n",
      "\n",
      "üìù Sample cleaned text:\n",
      "   Original: I signed a purchase agreement with Lennar Corporation on XX/XX/year>, for a new construction home in...\n",
      "   Cleaned:  i signed a purchase agreement with lennar corporation on xx xx year for a new construction home in x...\n",
      "   Length:   276 words\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Clean text\n",
    "df_final = prepare_final_dataset(df_filtered)\n",
    "print(\"‚úÖ Text cleaning complete\")\n",
    "\n",
    "# Show sample\n",
    "sample = df_final.iloc[0]\n",
    "print(f\"\\nüìù Sample cleaned text:\")\n",
    "print(f\"   Original: {sample['Consumer complaint narrative'][:100]}...\")\n",
    "print(f\"   Cleaned:  {sample['Cleaned_Narrative'][:100]}...\")\n",
    "print(f\"   Length:   {sample['Word_Count']} words\")  # Changed from Text_Length_Words to Word_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 265,694 complaints to d:\\10 acadamy\\Intelligent Complaint Analysis for Financial Services\\notebooks\\..\\data\\processed\\filtered_complaints.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Save data\n",
    "from src.config import PROCESSED_DATA_PATH\n",
    "\n",
    "final_cols = [\n",
    "    'Complaint ID', 'Date received', 'Product', 'Product_Category',\n",
    "    'Issue', 'Company', 'State', 'Consumer complaint narrative',\n",
    "    'Cleaned_Narrative', 'Text_Length_Chars', 'Text_Length_Words'\n",
    "]\n",
    "\n",
    "# Use df_final instead of business_df_viable\n",
    "final_df = df_final[[c for c in final_cols if c in df_final.columns]]\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "PROCESSED_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = PROCESSED_DATA_PATH / 'filtered_complaints.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Saved {len(final_df):,} complaints to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf1d78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 8: Report\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create reports directory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m reports_path = \u001b[43mPath\u001b[49m(PROCESSED_DATA_PATH).parent / \u001b[33m'\u001b[39m\u001b[33mreports\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m reports_path.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìÅ Reports directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreports_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 8: Report\n",
    "from pathlib import Path\n",
    "from src.config import PROCESSED_DATA_PATH\n",
    "\n",
    "# Create reports directory\n",
    "reports_path = Path(PROCESSED_DATA_PATH).parent / 'reports'\n",
    "reports_path.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Reports directory: {reports_path}\")\n",
    "\n",
    "# Save report\n",
    "report_path = reports_path / \"task1_quality_report.json\"\n",
    "report = save_data_quality_report(df_final, report_path)\n",
    "print(f\"‚úÖ Report saved to {report_path}\")\n",
    "\n",
    "# Generate summary\n",
    "summary = generate_task1_summary(df_final, df_final['Product_Category'].value_counts())\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1697e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Final statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä FINAL DATASET STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìà Product distribution:\")\n",
    "product_dist = final_df['Product_Category'].value_counts()\n",
    "for product, count in product_dist.items():\n",
    "    print(f\"   ‚Ä¢ {product}: {count:,} ({count/len(final_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìè Text length statistics:\")\n",
    "print(f\"   ‚Ä¢ Mean: {final_df['Text_Length_Words'].mean():.0f} words\")\n",
    "print(f\"   ‚Ä¢ Median: {final_df['Text_Length_Words'].median():.0f} words\")\n",
    "print(f\"   ‚Ä¢ Min: {final_df['Text_Length_Words'].min()} words\")\n",
    "print(f\"   ‚Ä¢ Max: {final_df['Text_Length_Words'].max():,} words\")\n",
    "\n",
    "print(f\"\\n‚úÖ TASK 1 COMPLETE - Ready for Task 2: Chunking & Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
